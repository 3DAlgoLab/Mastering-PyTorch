{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eps=50\n",
    "bsize=32\n",
    "lrate=0.001\n",
    "lat_dimension=64\n",
    "image_sz=64\n",
    "chnls=3\n",
    "logging_intv=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANGenerator, self).__init__()\n",
    "        self.inp_sz = image_sz // 4\n",
    "        self.lin = nn.Sequential(nn.Linear(lat_dimension, 128 * self.inp_sz ** 2))\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.up1 = nn.Upsample(scale_factor=2)\n",
    "        self.cn1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.rl1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.up2 = nn.Upsample(scale_factor=2)\n",
    "        self.cn2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.rl2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.cn3 = nn.Conv2d(64, chnls, 3, stride=1, padding=1)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = x.view(x.shape[0], 128, self.inp_sz, self.inp_sz)\n",
    "        x = self.bn1(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.cn1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.cn2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.rl2(x)\n",
    "        x = self.cn3(x)\n",
    "        out = self.act(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANDiscriminator, self).__init__()\n",
    "\n",
    "        def disc_module(ip_chnls, op_chnls, bnorm=True):\n",
    "            mod = [nn.Conv2d(ip_chnls, op_chnls, 3, 2, 1), \n",
    "                   nn.LeakyReLU(0.2, inplace=True), \n",
    "                   nn.Dropout2d(0.25)]\n",
    "            if bnorm:\n",
    "                mod += [nn.BatchNorm2d(op_chnls, 0.8)]\n",
    "            return mod\n",
    "\n",
    "        self.disc_model = nn.Sequential(\n",
    "            *disc_module(chnls, 16, bnorm=False),\n",
    "            *disc_module(16, 32),\n",
    "            *disc_module(32, 64),\n",
    "            *disc_module(64, 128),\n",
    "        )\n",
    "\n",
    "        # width and height of the down-sized image\n",
    "        ds_size = image_sz // 2 ** 4\n",
    "        self.adverse_lyr = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.disc_model(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        out = self.adverse_lyr(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the discriminator and generator models\n",
    "gen = GANGenerator()\n",
    "disc = GANDiscriminator()\n",
    "\n",
    "# define the loss metric\n",
    "adv_loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataset and corresponding dataloader\n",
    "dloader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(\n",
    "        \"./data/mnist/\",\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize((image_sz, image_sz)), \n",
    "             transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=bsize,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# define the optimization schedule for both G and D\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lrate)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 0 | batch number 0 | generator loss = 0.703317 | discriminator loss = 0.693092\n",
      "epoch number 0 | batch number 200 | generator loss = 3.520811 | discriminator loss = 0.097897\n",
      "epoch number 0 | batch number 400 | generator loss = 0.086716 | discriminator loss = 2.107819\n",
      "epoch number 0 | batch number 600 | generator loss = 2.876380 | discriminator loss = 0.613213\n",
      "epoch number 0 | batch number 800 | generator loss = 3.257680 | discriminator loss = 0.336500\n",
      "epoch number 0 | batch number 1000 | generator loss = 1.235065 | discriminator loss = 0.663049\n",
      "epoch number 0 | batch number 1200 | generator loss = 1.009370 | discriminator loss = 0.554212\n",
      "epoch number 0 | batch number 1400 | generator loss = 1.388542 | discriminator loss = 0.472908\n",
      "epoch number 0 | batch number 1600 | generator loss = 1.012620 | discriminator loss = 0.578827\n",
      "epoch number 0 | batch number 1800 | generator loss = 1.140438 | discriminator loss = 1.165913\n",
      "epoch number 0 | batch number 2000 | generator loss = 2.539284 | discriminator loss = 0.457855\n",
      "epoch number 0 | batch number 2200 | generator loss = 1.406052 | discriminator loss = 0.573906\n",
      "epoch number 0 | batch number 2400 | generator loss = 1.253656 | discriminator loss = 0.580756\n",
      "epoch number 0 | batch number 2600 | generator loss = 0.810509 | discriminator loss = 0.770427\n",
      "epoch number 0 | batch number 2800 | generator loss = 1.480727 | discriminator loss = 0.657454\n",
      "epoch number 0 | batch number 3000 | generator loss = 1.450391 | discriminator loss = 0.522204\n",
      "epoch number 0 | batch number 3200 | generator loss = 1.279605 | discriminator loss = 0.605447\n",
      "epoch number 0 | batch number 3400 | generator loss = 1.333656 | discriminator loss = 0.487989\n",
      "epoch number 0 | batch number 3600 | generator loss = 0.635696 | discriminator loss = 0.878987\n",
      "epoch number 0 | batch number 3800 | generator loss = 1.177884 | discriminator loss = 0.666506\n",
      "epoch number 0 | batch number 4000 | generator loss = 1.249212 | discriminator loss = 0.449666\n",
      "epoch number 0 | batch number 4200 | generator loss = 1.376662 | discriminator loss = 0.708707\n",
      "epoch number 0 | batch number 4400 | generator loss = 1.038805 | discriminator loss = 0.646013\n",
      "epoch number 0 | batch number 4600 | generator loss = 0.417899 | discriminator loss = 0.867919\n",
      "epoch number 0 | batch number 4800 | generator loss = 0.935188 | discriminator loss = 0.736136\n",
      "epoch number 0 | batch number 5000 | generator loss = 1.193912 | discriminator loss = 0.716746\n",
      "epoch number 0 | batch number 5200 | generator loss = 1.209525 | discriminator loss = 0.667474\n",
      "epoch number 0 | batch number 5400 | generator loss = 0.899696 | discriminator loss = 0.854051\n",
      "epoch number 0 | batch number 5600 | generator loss = 0.972726 | discriminator loss = 0.913076\n",
      "epoch number 0 | batch number 5800 | generator loss = 1.336670 | discriminator loss = 0.550333\n",
      "epoch number 0 | batch number 6000 | generator loss = 0.749094 | discriminator loss = 0.668815\n",
      "epoch number 0 | batch number 6200 | generator loss = 0.561049 | discriminator loss = 0.920200\n",
      "epoch number 1 | batch number 68 | generator loss = 0.951293 | discriminator loss = 0.880999\n",
      "epoch number 1 | batch number 268 | generator loss = 0.716177 | discriminator loss = 0.623316\n",
      "epoch number 1 | batch number 468 | generator loss = 0.909271 | discriminator loss = 0.628351\n",
      "epoch number 1 | batch number 668 | generator loss = 1.131823 | discriminator loss = 0.601978\n",
      "epoch number 1 | batch number 868 | generator loss = 1.325084 | discriminator loss = 0.548138\n",
      "epoch number 1 | batch number 1068 | generator loss = 0.619476 | discriminator loss = 0.709017\n",
      "epoch number 1 | batch number 1268 | generator loss = 1.153831 | discriminator loss = 0.516372\n",
      "epoch number 1 | batch number 1468 | generator loss = 0.568315 | discriminator loss = 0.594451\n",
      "epoch number 1 | batch number 1668 | generator loss = 1.000156 | discriminator loss = 0.439631\n",
      "epoch number 1 | batch number 1868 | generator loss = 0.745624 | discriminator loss = 0.753575\n",
      "epoch number 1 | batch number 2068 | generator loss = 0.943694 | discriminator loss = 0.544337\n",
      "epoch number 1 | batch number 2268 | generator loss = 0.842952 | discriminator loss = 0.632348\n",
      "epoch number 1 | batch number 2468 | generator loss = 0.928161 | discriminator loss = 0.622360\n",
      "epoch number 1 | batch number 2668 | generator loss = 0.887456 | discriminator loss = 0.674502\n",
      "epoch number 1 | batch number 2868 | generator loss = 1.039681 | discriminator loss = 0.628694\n",
      "epoch number 1 | batch number 3068 | generator loss = 0.925151 | discriminator loss = 0.723141\n",
      "epoch number 1 | batch number 3268 | generator loss = 0.937701 | discriminator loss = 0.605375\n",
      "epoch number 1 | batch number 3468 | generator loss = 0.845467 | discriminator loss = 0.537818\n",
      "epoch number 1 | batch number 3668 | generator loss = 0.878810 | discriminator loss = 0.675182\n",
      "epoch number 1 | batch number 3868 | generator loss = 0.819623 | discriminator loss = 0.626582\n",
      "epoch number 1 | batch number 4068 | generator loss = 0.667383 | discriminator loss = 0.651203\n",
      "epoch number 1 | batch number 4268 | generator loss = 1.048776 | discriminator loss = 0.620608\n",
      "epoch number 1 | batch number 4468 | generator loss = 0.741723 | discriminator loss = 0.714854\n",
      "epoch number 1 | batch number 4668 | generator loss = 0.983842 | discriminator loss = 0.572628\n",
      "epoch number 1 | batch number 4868 | generator loss = 0.936638 | discriminator loss = 0.645666\n",
      "epoch number 1 | batch number 5068 | generator loss = 0.737005 | discriminator loss = 0.659432\n",
      "epoch number 1 | batch number 5268 | generator loss = 0.901110 | discriminator loss = 0.796598\n",
      "epoch number 1 | batch number 5468 | generator loss = 0.764757 | discriminator loss = 0.865092\n",
      "epoch number 1 | batch number 5668 | generator loss = 0.726424 | discriminator loss = 0.721730\n",
      "epoch number 1 | batch number 5868 | generator loss = 0.981133 | discriminator loss = 0.635811\n",
      "epoch number 1 | batch number 6068 | generator loss = 0.796752 | discriminator loss = 0.669892\n",
      "epoch number 1 | batch number 6268 | generator loss = 0.811231 | discriminator loss = 0.710177\n",
      "epoch number 2 | batch number 136 | generator loss = 0.694388 | discriminator loss = 0.600215\n",
      "epoch number 2 | batch number 336 | generator loss = 0.771121 | discriminator loss = 0.696135\n",
      "epoch number 2 | batch number 536 | generator loss = 0.776883 | discriminator loss = 0.736604\n",
      "epoch number 2 | batch number 736 | generator loss = 0.985535 | discriminator loss = 0.548536\n",
      "epoch number 2 | batch number 936 | generator loss = 0.794398 | discriminator loss = 0.663867\n",
      "epoch number 2 | batch number 1136 | generator loss = 0.816226 | discriminator loss = 0.714332\n",
      "epoch number 2 | batch number 1336 | generator loss = 0.717381 | discriminator loss = 0.725673\n",
      "epoch number 2 | batch number 1536 | generator loss = 0.808639 | discriminator loss = 0.648863\n",
      "epoch number 2 | batch number 1736 | generator loss = 0.931851 | discriminator loss = 0.552903\n",
      "epoch number 2 | batch number 1936 | generator loss = 0.596344 | discriminator loss = 0.648382\n",
      "epoch number 2 | batch number 2136 | generator loss = 0.777213 | discriminator loss = 0.710246\n",
      "epoch number 2 | batch number 2336 | generator loss = 0.859244 | discriminator loss = 0.696924\n",
      "epoch number 2 | batch number 2536 | generator loss = 0.745279 | discriminator loss = 0.688399\n",
      "epoch number 2 | batch number 2736 | generator loss = 0.811675 | discriminator loss = 0.533748\n",
      "epoch number 2 | batch number 2936 | generator loss = 0.941370 | discriminator loss = 0.696691\n",
      "epoch number 2 | batch number 3136 | generator loss = 0.826527 | discriminator loss = 0.672197\n",
      "epoch number 2 | batch number 3336 | generator loss = 0.789807 | discriminator loss = 0.638093\n",
      "epoch number 2 | batch number 3536 | generator loss = 0.763330 | discriminator loss = 0.671191\n",
      "epoch number 2 | batch number 3736 | generator loss = 0.696186 | discriminator loss = 0.707337\n",
      "epoch number 2 | batch number 3936 | generator loss = 1.062149 | discriminator loss = 0.648247\n",
      "epoch number 2 | batch number 4136 | generator loss = 0.874934 | discriminator loss = 0.722729\n",
      "epoch number 2 | batch number 4336 | generator loss = 0.679172 | discriminator loss = 0.710095\n",
      "epoch number 2 | batch number 4536 | generator loss = 0.721856 | discriminator loss = 0.766797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 2 | batch number 4736 | generator loss = 0.569593 | discriminator loss = 0.858146\n",
      "epoch number 2 | batch number 4936 | generator loss = 1.062639 | discriminator loss = 0.519092\n",
      "epoch number 2 | batch number 5136 | generator loss = 0.899736 | discriminator loss = 0.702106\n",
      "epoch number 2 | batch number 5336 | generator loss = 0.830697 | discriminator loss = 0.591507\n",
      "epoch number 2 | batch number 5536 | generator loss = 0.978978 | discriminator loss = 0.696458\n",
      "epoch number 2 | batch number 5736 | generator loss = 1.071144 | discriminator loss = 0.854599\n",
      "epoch number 2 | batch number 5936 | generator loss = 0.656397 | discriminator loss = 0.623073\n",
      "epoch number 2 | batch number 6136 | generator loss = 0.798755 | discriminator loss = 0.644222\n",
      "epoch number 3 | batch number 4 | generator loss = 1.033044 | discriminator loss = 0.541450\n",
      "epoch number 3 | batch number 204 | generator loss = 0.994769 | discriminator loss = 0.729598\n",
      "epoch number 3 | batch number 404 | generator loss = 0.825712 | discriminator loss = 0.709631\n",
      "epoch number 3 | batch number 604 | generator loss = 0.983929 | discriminator loss = 0.565983\n",
      "epoch number 3 | batch number 804 | generator loss = 0.689695 | discriminator loss = 0.598365\n",
      "epoch number 3 | batch number 1004 | generator loss = 0.949197 | discriminator loss = 0.632753\n",
      "epoch number 3 | batch number 1204 | generator loss = 0.993490 | discriminator loss = 0.481382\n",
      "epoch number 3 | batch number 1404 | generator loss = 1.003181 | discriminator loss = 0.639453\n",
      "epoch number 3 | batch number 1604 | generator loss = 0.967539 | discriminator loss = 0.661285\n",
      "epoch number 3 | batch number 1804 | generator loss = 0.964599 | discriminator loss = 0.728261\n",
      "epoch number 3 | batch number 2004 | generator loss = 0.631250 | discriminator loss = 0.657802\n",
      "epoch number 3 | batch number 2204 | generator loss = 0.595850 | discriminator loss = 0.717068\n",
      "epoch number 3 | batch number 2404 | generator loss = 0.933562 | discriminator loss = 0.639137\n",
      "epoch number 3 | batch number 2604 | generator loss = 1.188705 | discriminator loss = 0.589593\n",
      "epoch number 3 | batch number 2804 | generator loss = 0.641071 | discriminator loss = 0.592058\n",
      "epoch number 3 | batch number 3004 | generator loss = 0.777159 | discriminator loss = 0.671771\n",
      "epoch number 3 | batch number 3204 | generator loss = 0.657771 | discriminator loss = 0.668219\n",
      "epoch number 3 | batch number 3404 | generator loss = 0.921041 | discriminator loss = 0.586594\n",
      "epoch number 3 | batch number 3604 | generator loss = 1.103795 | discriminator loss = 0.640740\n",
      "epoch number 3 | batch number 3804 | generator loss = 1.276220 | discriminator loss = 0.568695\n",
      "epoch number 3 | batch number 4004 | generator loss = 0.701900 | discriminator loss = 0.663598\n",
      "epoch number 3 | batch number 4204 | generator loss = 1.093809 | discriminator loss = 0.631606\n",
      "epoch number 3 | batch number 4404 | generator loss = 1.139024 | discriminator loss = 0.724051\n",
      "epoch number 3 | batch number 4604 | generator loss = 0.610120 | discriminator loss = 0.592368\n",
      "epoch number 3 | batch number 4804 | generator loss = 0.542153 | discriminator loss = 0.784642\n",
      "epoch number 3 | batch number 5004 | generator loss = 1.207309 | discriminator loss = 0.431373\n",
      "epoch number 3 | batch number 5204 | generator loss = 0.987975 | discriminator loss = 0.503829\n",
      "epoch number 3 | batch number 5404 | generator loss = 1.061003 | discriminator loss = 0.792831\n",
      "epoch number 3 | batch number 5604 | generator loss = 1.181087 | discriminator loss = 0.530835\n",
      "epoch number 3 | batch number 5804 | generator loss = 1.032630 | discriminator loss = 0.535389\n",
      "epoch number 3 | batch number 6004 | generator loss = 1.017700 | discriminator loss = 0.777419\n",
      "epoch number 3 | batch number 6204 | generator loss = 0.807663 | discriminator loss = 0.626374\n",
      "epoch number 4 | batch number 72 | generator loss = 0.607943 | discriminator loss = 0.576183\n",
      "epoch number 4 | batch number 272 | generator loss = 1.019803 | discriminator loss = 0.800895\n",
      "epoch number 4 | batch number 472 | generator loss = 1.158322 | discriminator loss = 0.733711\n",
      "epoch number 4 | batch number 672 | generator loss = 0.884175 | discriminator loss = 0.552251\n",
      "epoch number 4 | batch number 872 | generator loss = 0.859573 | discriminator loss = 0.568565\n",
      "epoch number 4 | batch number 1072 | generator loss = 0.971507 | discriminator loss = 0.577314\n",
      "epoch number 4 | batch number 1272 | generator loss = 0.634721 | discriminator loss = 0.658456\n",
      "epoch number 4 | batch number 1472 | generator loss = 0.771910 | discriminator loss = 0.847478\n",
      "epoch number 4 | batch number 1672 | generator loss = 1.023481 | discriminator loss = 0.698293\n",
      "epoch number 4 | batch number 1872 | generator loss = 0.624178 | discriminator loss = 0.649235\n",
      "epoch number 4 | batch number 2072 | generator loss = 0.812892 | discriminator loss = 0.793473\n",
      "epoch number 4 | batch number 2272 | generator loss = 0.924367 | discriminator loss = 0.525197\n",
      "epoch number 4 | batch number 2472 | generator loss = 0.839511 | discriminator loss = 0.626225\n",
      "epoch number 4 | batch number 2672 | generator loss = 0.817473 | discriminator loss = 0.619049\n",
      "epoch number 4 | batch number 2872 | generator loss = 0.902566 | discriminator loss = 0.847710\n",
      "epoch number 4 | batch number 3072 | generator loss = 0.974934 | discriminator loss = 0.684256\n",
      "epoch number 4 | batch number 3272 | generator loss = 0.817317 | discriminator loss = 0.693280\n",
      "epoch number 4 | batch number 3472 | generator loss = 1.183138 | discriminator loss = 0.683464\n",
      "epoch number 4 | batch number 3672 | generator loss = 1.159791 | discriminator loss = 0.574197\n",
      "epoch number 4 | batch number 3872 | generator loss = 0.691656 | discriminator loss = 0.672352\n",
      "epoch number 4 | batch number 4072 | generator loss = 1.028016 | discriminator loss = 0.556275\n",
      "epoch number 4 | batch number 4272 | generator loss = 0.948484 | discriminator loss = 0.486209\n",
      "epoch number 4 | batch number 4472 | generator loss = 0.841509 | discriminator loss = 0.578450\n",
      "epoch number 4 | batch number 4672 | generator loss = 0.543018 | discriminator loss = 0.534322\n",
      "epoch number 4 | batch number 4872 | generator loss = 1.057691 | discriminator loss = 0.595802\n",
      "epoch number 4 | batch number 5072 | generator loss = 0.897398 | discriminator loss = 0.915996\n",
      "epoch number 4 | batch number 5272 | generator loss = 0.698377 | discriminator loss = 0.587102\n",
      "epoch number 4 | batch number 5472 | generator loss = 1.088683 | discriminator loss = 0.509399\n",
      "epoch number 4 | batch number 5672 | generator loss = 0.575726 | discriminator loss = 0.745460\n",
      "epoch number 4 | batch number 5872 | generator loss = 0.827424 | discriminator loss = 0.452655\n",
      "epoch number 4 | batch number 6072 | generator loss = 0.938612 | discriminator loss = 0.350873\n",
      "epoch number 4 | batch number 6272 | generator loss = 0.620065 | discriminator loss = 0.594088\n",
      "epoch number 5 | batch number 140 | generator loss = 0.628281 | discriminator loss = 0.769709\n",
      "epoch number 5 | batch number 340 | generator loss = 1.115707 | discriminator loss = 0.780161\n",
      "epoch number 5 | batch number 540 | generator loss = 0.744562 | discriminator loss = 0.639692\n",
      "epoch number 5 | batch number 740 | generator loss = 0.605176 | discriminator loss = 0.437695\n",
      "epoch number 5 | batch number 940 | generator loss = 1.006511 | discriminator loss = 0.538790\n",
      "epoch number 5 | batch number 1140 | generator loss = 0.619896 | discriminator loss = 0.576682\n",
      "epoch number 5 | batch number 1340 | generator loss = 0.819049 | discriminator loss = 0.724968\n",
      "epoch number 5 | batch number 1540 | generator loss = 1.018934 | discriminator loss = 0.654515\n",
      "epoch number 5 | batch number 1740 | generator loss = 1.457298 | discriminator loss = 0.510560\n",
      "epoch number 5 | batch number 1940 | generator loss = 1.006408 | discriminator loss = 0.523088\n",
      "epoch number 5 | batch number 2140 | generator loss = 0.919872 | discriminator loss = 0.785275\n",
      "epoch number 5 | batch number 2340 | generator loss = 0.891186 | discriminator loss = 0.504302\n",
      "epoch number 5 | batch number 2540 | generator loss = 0.754659 | discriminator loss = 0.611799\n",
      "epoch number 5 | batch number 2740 | generator loss = 0.884051 | discriminator loss = 0.713241\n",
      "epoch number 5 | batch number 2940 | generator loss = 0.914601 | discriminator loss = 0.539608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 5 | batch number 3140 | generator loss = 0.676439 | discriminator loss = 0.660038\n",
      "epoch number 5 | batch number 3340 | generator loss = 0.691239 | discriminator loss = 0.662879\n",
      "epoch number 5 | batch number 3540 | generator loss = 0.767506 | discriminator loss = 0.611993\n",
      "epoch number 5 | batch number 3740 | generator loss = 1.141797 | discriminator loss = 0.769062\n",
      "epoch number 5 | batch number 3940 | generator loss = 1.065294 | discriminator loss = 0.629925\n",
      "epoch number 5 | batch number 4140 | generator loss = 1.110013 | discriminator loss = 0.523894\n",
      "epoch number 5 | batch number 4340 | generator loss = 0.741305 | discriminator loss = 0.424061\n",
      "epoch number 5 | batch number 4540 | generator loss = 0.582408 | discriminator loss = 0.558700\n",
      "epoch number 5 | batch number 4740 | generator loss = 1.102569 | discriminator loss = 0.613773\n",
      "epoch number 5 | batch number 4940 | generator loss = 0.642278 | discriminator loss = 0.554472\n",
      "epoch number 5 | batch number 5140 | generator loss = 0.767773 | discriminator loss = 0.651325\n",
      "epoch number 5 | batch number 5340 | generator loss = 0.746787 | discriminator loss = 0.605405\n",
      "epoch number 5 | batch number 5540 | generator loss = 0.484277 | discriminator loss = 0.667036\n",
      "epoch number 5 | batch number 5740 | generator loss = 0.805469 | discriminator loss = 0.637113\n",
      "epoch number 5 | batch number 5940 | generator loss = 0.696023 | discriminator loss = 0.591585\n",
      "epoch number 5 | batch number 6140 | generator loss = 0.752201 | discriminator loss = 0.559423\n",
      "epoch number 6 | batch number 8 | generator loss = 0.437953 | discriminator loss = 0.666981\n",
      "epoch number 6 | batch number 208 | generator loss = 0.930437 | discriminator loss = 0.675221\n",
      "epoch number 6 | batch number 408 | generator loss = 0.360146 | discriminator loss = 1.390621\n",
      "epoch number 6 | batch number 608 | generator loss = 0.816309 | discriminator loss = 0.533718\n",
      "epoch number 6 | batch number 808 | generator loss = 1.014673 | discriminator loss = 0.604489\n",
      "epoch number 6 | batch number 1008 | generator loss = 0.897761 | discriminator loss = 0.774941\n",
      "epoch number 6 | batch number 1208 | generator loss = 1.223542 | discriminator loss = 0.583753\n",
      "epoch number 6 | batch number 1408 | generator loss = 0.789528 | discriminator loss = 0.619581\n",
      "epoch number 6 | batch number 1608 | generator loss = 0.491135 | discriminator loss = 0.614689\n",
      "epoch number 6 | batch number 1808 | generator loss = 0.810440 | discriminator loss = 0.564405\n",
      "epoch number 6 | batch number 2008 | generator loss = 1.117365 | discriminator loss = 0.606084\n",
      "epoch number 6 | batch number 2208 | generator loss = 0.803620 | discriminator loss = 0.701339\n",
      "epoch number 6 | batch number 2408 | generator loss = 1.020138 | discriminator loss = 0.694589\n",
      "epoch number 6 | batch number 2608 | generator loss = 0.722069 | discriminator loss = 0.652289\n",
      "epoch number 6 | batch number 2808 | generator loss = 0.961122 | discriminator loss = 0.871033\n",
      "epoch number 6 | batch number 3008 | generator loss = 1.087560 | discriminator loss = 0.656938\n",
      "epoch number 6 | batch number 3208 | generator loss = 0.805401 | discriminator loss = 0.719543\n",
      "epoch number 6 | batch number 3408 | generator loss = 0.609603 | discriminator loss = 0.665168\n",
      "epoch number 6 | batch number 3608 | generator loss = 1.053313 | discriminator loss = 0.499711\n",
      "epoch number 6 | batch number 3808 | generator loss = 1.048677 | discriminator loss = 0.747617\n",
      "epoch number 6 | batch number 4008 | generator loss = 0.725365 | discriminator loss = 0.662777\n",
      "epoch number 6 | batch number 4208 | generator loss = 0.603538 | discriminator loss = 0.694275\n",
      "epoch number 6 | batch number 4408 | generator loss = 0.629774 | discriminator loss = 0.647944\n",
      "epoch number 6 | batch number 4608 | generator loss = 0.851899 | discriminator loss = 0.695155\n",
      "epoch number 6 | batch number 4808 | generator loss = 0.810076 | discriminator loss = 0.785869\n",
      "epoch number 6 | batch number 5008 | generator loss = 1.067658 | discriminator loss = 0.467511\n",
      "epoch number 6 | batch number 5208 | generator loss = 0.903841 | discriminator loss = 0.675904\n",
      "epoch number 6 | batch number 5408 | generator loss = 0.473937 | discriminator loss = 0.734868\n",
      "epoch number 6 | batch number 5608 | generator loss = 0.781959 | discriminator loss = 0.776281\n",
      "epoch number 6 | batch number 5808 | generator loss = 0.725392 | discriminator loss = 0.641123\n",
      "epoch number 6 | batch number 6008 | generator loss = 0.920828 | discriminator loss = 0.565429\n",
      "epoch number 6 | batch number 6208 | generator loss = 0.874067 | discriminator loss = 0.680002\n",
      "epoch number 7 | batch number 76 | generator loss = 0.833922 | discriminator loss = 0.724807\n",
      "epoch number 7 | batch number 276 | generator loss = 0.671457 | discriminator loss = 0.639777\n",
      "epoch number 7 | batch number 476 | generator loss = 0.809737 | discriminator loss = 0.529229\n",
      "epoch number 7 | batch number 676 | generator loss = 0.690222 | discriminator loss = 0.468965\n",
      "epoch number 7 | batch number 876 | generator loss = 0.626693 | discriminator loss = 0.726543\n",
      "epoch number 7 | batch number 1076 | generator loss = 0.902819 | discriminator loss = 0.613331\n",
      "epoch number 7 | batch number 1276 | generator loss = 0.648491 | discriminator loss = 0.653547\n",
      "epoch number 7 | batch number 1476 | generator loss = 0.495594 | discriminator loss = 0.745759\n",
      "epoch number 7 | batch number 1676 | generator loss = 0.640377 | discriminator loss = 0.797008\n",
      "epoch number 7 | batch number 1876 | generator loss = 0.985557 | discriminator loss = 0.628037\n",
      "epoch number 7 | batch number 2076 | generator loss = 1.362713 | discriminator loss = 0.797937\n",
      "epoch number 7 | batch number 2276 | generator loss = 0.714615 | discriminator loss = 0.799678\n",
      "epoch number 7 | batch number 2476 | generator loss = 0.716119 | discriminator loss = 0.559345\n",
      "epoch number 7 | batch number 2676 | generator loss = 0.609081 | discriminator loss = 0.565428\n",
      "epoch number 7 | batch number 2876 | generator loss = 1.068487 | discriminator loss = 0.609745\n",
      "epoch number 7 | batch number 3076 | generator loss = 0.853648 | discriminator loss = 0.600683\n",
      "epoch number 7 | batch number 3276 | generator loss = 0.925885 | discriminator loss = 0.708149\n",
      "epoch number 7 | batch number 3476 | generator loss = 0.623898 | discriminator loss = 0.715639\n",
      "epoch number 7 | batch number 3676 | generator loss = 1.063965 | discriminator loss = 0.684613\n",
      "epoch number 7 | batch number 3876 | generator loss = 1.702576 | discriminator loss = 0.575011\n",
      "epoch number 7 | batch number 4076 | generator loss = 0.906546 | discriminator loss = 0.462750\n",
      "epoch number 7 | batch number 4276 | generator loss = 0.684472 | discriminator loss = 0.558581\n",
      "epoch number 7 | batch number 4476 | generator loss = 1.097462 | discriminator loss = 0.473613\n",
      "epoch number 7 | batch number 4676 | generator loss = 1.019820 | discriminator loss = 0.505393\n",
      "epoch number 7 | batch number 4876 | generator loss = 0.901326 | discriminator loss = 0.699535\n",
      "epoch number 7 | batch number 5076 | generator loss = 0.634227 | discriminator loss = 0.511222\n",
      "epoch number 7 | batch number 5276 | generator loss = 0.788600 | discriminator loss = 0.648748\n",
      "epoch number 7 | batch number 5476 | generator loss = 0.831032 | discriminator loss = 0.571355\n",
      "epoch number 7 | batch number 5676 | generator loss = 0.959776 | discriminator loss = 0.698601\n",
      "epoch number 7 | batch number 5876 | generator loss = 0.665067 | discriminator loss = 0.704834\n",
      "epoch number 7 | batch number 6076 | generator loss = 0.844039 | discriminator loss = 0.889709\n",
      "epoch number 7 | batch number 6276 | generator loss = 1.106719 | discriminator loss = 0.787475\n",
      "epoch number 8 | batch number 144 | generator loss = 0.705335 | discriminator loss = 0.550944\n",
      "epoch number 8 | batch number 344 | generator loss = 0.530180 | discriminator loss = 0.556397\n",
      "epoch number 8 | batch number 544 | generator loss = 0.770897 | discriminator loss = 0.552160\n",
      "epoch number 8 | batch number 744 | generator loss = 1.178249 | discriminator loss = 0.431259\n",
      "epoch number 8 | batch number 944 | generator loss = 0.881033 | discriminator loss = 0.465235\n",
      "epoch number 8 | batch number 1144 | generator loss = 0.855142 | discriminator loss = 0.508350\n",
      "epoch number 8 | batch number 1344 | generator loss = 1.092256 | discriminator loss = 0.620883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number 8 | batch number 1544 | generator loss = 1.579486 | discriminator loss = 0.797279\n",
      "epoch number 8 | batch number 1744 | generator loss = 0.989263 | discriminator loss = 0.620146\n",
      "epoch number 8 | batch number 1944 | generator loss = 0.853543 | discriminator loss = 0.710362\n",
      "epoch number 8 | batch number 2144 | generator loss = 1.103519 | discriminator loss = 0.630420\n",
      "epoch number 8 | batch number 2344 | generator loss = 0.757749 | discriminator loss = 0.805621\n",
      "epoch number 8 | batch number 2544 | generator loss = 1.479676 | discriminator loss = 0.451883\n",
      "epoch number 8 | batch number 2744 | generator loss = 0.855336 | discriminator loss = 0.540650\n"
     ]
    }
   ],
   "source": [
    "for ep in range(num_eps):\n",
    "    for idx, (images, _) in enumerate(dloader):\n",
    "\n",
    "        # generate grounnd truths for real and fake images\n",
    "        good_img = Variable(torch.FloatTensor(images.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        bad_img = Variable(torch.FloatTensor(images.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # get a real image\n",
    "        actual_images = Variable(images.type(torch.FloatTensor))\n",
    "\n",
    "        # train the generator model\n",
    "        opt_gen.zero_grad()\n",
    "\n",
    "        # generate a batch of images based on random noise as input\n",
    "        noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (images.shape[0], lat_dimension))))\n",
    "        gen_images = gen(noise)\n",
    "\n",
    "        # generator model optimization - how well can it fool the discriminator\n",
    "        generator_loss = adv_loss_func(disc(gen_images), good_img)\n",
    "        generator_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # train the discriminator model\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        # calculate discriminator loss as average of mistakes(losses) in confusing real images as fake and vice versa\n",
    "        actual_image_loss = adv_loss_func(disc(actual_images), good_img)\n",
    "        fake_image_loss = adv_loss_func(disc(gen_images.detach()), bad_img)\n",
    "        discriminator_loss = (actual_image_loss + fake_image_loss) / 2\n",
    "\n",
    "        # discriminator model optimization\n",
    "        discriminator_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        batches_completed = ep * len(dloader) + idx\n",
    "        if batches_completed % logging_intv == 0:\n",
    "            print(f\"epoch number {ep} | batch number {idx} | generator loss = {generator_loss.item()} \\\n",
    "            | discriminator loss = {discriminator_loss.item()}\")\n",
    "            save_image(gen_images.data[:25], f\"images_mnist/{batches_completed}.png\", nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
